{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlpR5ZyjeTDTwkMikEcrDI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/menaxyz/final_AI/blob/main/final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shiyun Zhou CS481 final\n"
      ],
      "metadata": {
        "id": "xXqpzbGuF7EC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1\n"
      ],
      "metadata": {
        "id": "vp_qTuKEGBRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "\n",
        "\n",
        "def find_path(came_from, start, goal):\n",
        "    current = goal\n",
        "    path = []\n",
        "\n",
        "    while current != start:\n",
        "        path.insert(0, current)\n",
        "        current = came_from[current]\n",
        "\n",
        "    path.insert(0, start)\n",
        "    return path\n",
        "\n",
        "\n",
        "def heuristic(a, b):\n",
        "    (x1, y1) = a\n",
        "    (x2, y2) = b\n",
        "    return abs(x1 - x2) + abs(y1 - y2)\n",
        "\n",
        "\n",
        "def find_neighbors(maze, current_position):\n",
        "    x, y = current_position\n",
        "    potential_neighbors = [(x + 1, y), (x - 1, y), (x, y + 1), (x, y - 1)]#NSEW\n",
        "\n",
        "    valid_neighbors = [\n",
        "    (nx, ny) for nx, ny in potential_neighbors if\n",
        "    0 <= nx < len(maze) and\n",
        "    0 <= ny < len(maze[0]) and\n",
        "    0 <= maze[nx][ny] < 2 ]\n",
        "\n",
        "    return valid_neighbors\n",
        "\n",
        "\n",
        "# A*\n",
        "def a_star_search(maze, start, goals):\n",
        "    frontier = []\n",
        "    heapq.heappush(frontier, (0, start))\n",
        "    before = {}\n",
        "    cost = {}\n",
        "    before[start] = None\n",
        "    cost[start] = 0\n",
        "\n",
        "    found_goals = []\n",
        "\n",
        "    while frontier:\n",
        "\n",
        "        _, current = heapq.heappop(frontier)\n",
        "        if current in goals and current not in found_goals:\n",
        "            found_goals.append(current)\n",
        "            if len(found_goals) == len(goals):\n",
        "                break\n",
        "\n",
        "        #find neighbors\n",
        "        for next in find_neighbors(maze, current):\n",
        "\n",
        "            new_cost = cost[current] + 1\n",
        "\n",
        "            if next not in cost or new_cost < cost[next]:\n",
        "                cost[next] = new_cost\n",
        "                priority = new_cost + heuristic(next, current)\n",
        "                heapq.heappush(frontier, (priority, next))\n",
        "                before[next] = current\n",
        "\n",
        "    paths = [find_path(before, start, goal) if goal in before else [] for goal in goals]\n",
        "    return paths\n",
        "\n",
        "\n",
        "maze = [\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
        "    [0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0],\n",
        "    [1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0],\n",
        "    [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1],\n",
        "    [0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0],\n",
        "    [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
        "    [0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0],\n",
        "    [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
        "]\n",
        "\n",
        "start = (10, 5)\n",
        "goal1 = [(0, 5)]\n",
        "goal2 = [(4, 2)]\n",
        "\n",
        "path1 = a_star_search(maze, start, goal1)\n",
        "print(\"Paths to goal1:\", path1)\n",
        "\n",
        "path2 = a_star_search(maze, start, goal2)\n",
        "print(\"Paths to goal2:\", path2)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smRQiqhgf8Ck",
        "outputId": "81984c1a-e889-4d72-9682-be051ee45392"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Paths to goal1: [[(10, 5), (9, 5), (8, 5), (7, 5), (6, 5), (5, 5), (4, 5), (3, 5), (2, 5), (1, 5), (0, 5)]]\n",
            "Paths to goal2: [[(10, 5), (9, 5), (8, 5), (7, 5), (6, 5), (5, 5), (4, 5), (4, 4), (4, 3), (4, 2)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2\n"
      ],
      "metadata": {
        "id": "YAz7ESbzkhnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def generate_states():\n",
        "\n",
        "    states = set()\n",
        "\n",
        "    generate_recursive(\"X---X---O\", states)\n",
        "\n",
        "    states_list = list(states)\n",
        "\n",
        "    states_dict = {state: get_child_states(state) for state in states_list}\n",
        "    return states_dict\n",
        "\n",
        "\n",
        "def all_possible_states(state, states):\n",
        "\n",
        "    if state not in states:\n",
        "\n",
        "        states.add(state)\n",
        "\n",
        "        for i in range(len(state)):\n",
        "\n",
        "            if state[i] == \"-\":\n",
        "\n",
        "                for symbol in ['X', 'O']:\n",
        "                    new_state = state[:i] + symbol + state[i+1:]\n",
        "                    all_possible_states(new_state, states)\n",
        "\n",
        "\n",
        "def get_child_states(state):\n",
        "\n",
        "    child_states = []\n",
        "    for i in range(len(state)):\n",
        "        if state[i] == \"-\":\n",
        "            for symbol in ['X', 'O']:\n",
        "                new_state = state[:i] + symbol + state[i+1:]\n",
        "                child_states.append(new_state)\n",
        "    return child_states\n",
        "\n",
        "def state_to_3x3_grid(state):\n",
        "    return [list(state[i:i+3]) for i in range(0, len(state), 3)]\n",
        "\n",
        "def save_to_json(states_dict, filename=\"tic_tac_toe_states.json\"):\n",
        "    formatted_states = {state: state_to_3x3_grid(state) for state in states_dict.keys()}\n",
        "    with open(filename, 'w') as file:\n",
        "        json.dump(formatted_states, file, indent=2)\n",
        "\n",
        "def print_board(state):\n",
        "    for row in state:\n",
        "        print(row)\n",
        "\n",
        "tic_tac_toe_states = generate_states()\n",
        "save_to_json(tic_tac_toe_states)\n",
        "\n",
        "print(\" tic_tac_toe_states.json saved .\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh21EyOgz0OY",
        "outputId": "20b2fa1a-8e43-44cf-b388-56359281f9a9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " tic_tac_toe_states.json saved .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3"
      ],
      "metadata": {
        "id": "R4DF-f91030b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], -1))\n",
        "x_test = x_test.reshape((x_test.shape[0], -1))\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(784,)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHplSUBe05Hz",
        "outputId": "21042c62-d972-49f6-83fb-06612634ab61"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.2886 - accuracy: 0.9181 - val_loss: 0.1553 - val_accuracy: 0.9554\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1288 - accuracy: 0.9617 - val_loss: 0.1148 - val_accuracy: 0.9652\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0888 - accuracy: 0.9736 - val_loss: 0.1116 - val_accuracy: 0.9676\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 11s 7ms/step - loss: 0.0661 - accuracy: 0.9797 - val_loss: 0.0959 - val_accuracy: 0.9721\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0504 - accuracy: 0.9841 - val_loss: 0.1021 - val_accuracy: 0.9713\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0395 - accuracy: 0.9879 - val_loss: 0.0867 - val_accuracy: 0.9746\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0326 - accuracy: 0.9895 - val_loss: 0.0843 - val_accuracy: 0.9743\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0250 - accuracy: 0.9926 - val_loss: 0.0964 - val_accuracy: 0.9746\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.0892 - val_accuracy: 0.9775\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0170 - accuracy: 0.9950 - val_loss: 0.0956 - val_accuracy: 0.9753\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9766\n",
            "Test accuracy: 97.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4\n"
      ],
      "metadata": {
        "id": "kjwErdee1uGb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "\n",
        "def load_data(test_split=0.2, seed=113):\n",
        "    data = fetch_california_housing()\n",
        "    x_train, x_test, y_train, y_test = train_test_split(data.data, data.target, test_size=test_split, random_state=seed)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test)\n",
        "\n",
        "def preprocess_data(x_train, x_test):\n",
        "    scaler = StandardScaler()\n",
        "    x_train_scaled = scaler.fit_transform(x_train)\n",
        "    x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "    return x_train_scaled, x_test_scaled\n",
        "\n",
        "def build_regression_model(input_shape):\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(input_shape,)),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_and_evaluate_model(model, x_train, y_train, x_test, y_test, epochs=50, batch_size=32):\n",
        "    model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
        "    y_pred = model.predict(x_test).flatten()\n",
        "\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "    return mse, mae\n",
        "\n",
        "\n",
        "def main():\n",
        "    (x_train, y_train), (x_test, y_test) = load_data()\n",
        "\n",
        "    x_train_scaled, x_test_scaled = preprocess_data(x_train, x_test)\n",
        "\n",
        "    model = build_regression_model(input_shape=x_train_scaled.shape[1])\n",
        "    mse, mae = train_and_evaluate_model(model, x_train_scaled, y_train, x_test_scaled, y_test)\n",
        "\n",
        "    print(f'MSE: {mse:.2f}')\n",
        "    print(f'MAE: {mae:.2f}')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SL_JRsB7EUw",
        "outputId": "27ca2571-b8a0-43a6-baaa-fb2324b43603"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "129/129 [==============================] - 0s 2ms/step\n",
            "MSE: 0.27\n",
            "MAE: 0.35\n"
          ]
        }
      ]
    }
  ]
}